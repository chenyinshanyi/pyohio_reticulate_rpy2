date_sequence = data_frame(
start=seq.Date(from=as.Date('2017-01-01'),
to=lubridate::today()-lubridate::days(1),
by='1 day'),
end=start+lubridate::days(1)
)
station = 'KSFO'
base_url = 'https://api.weather.gov/stations/'
resource = '/observations?'
start_time = 'T00%3A56%3A00%2B00%3A00&'
end_time = 'T23%3A56%3A00%2B00%3A00'
date_sequence = data_frame(
start=seq.Date(from=as.Date('2018-06-01'),
to=lubridate::today()-lubridate::days(1),
by='1 day'),
end=start+lubridate::days(1)
)
station = 'KSFO'
base_url = 'https://api.weather.gov/stations/'
resource = '/observations?'
start_time = 'T00%3A56%3A00%2B00%3A00&'
end_time = 'T23%3A56%3A00%2B00%3A00'
for (i in seq_along(date_sequence$start)){
start_date = date_sequence$start[i]
end_date = date_sequence$end[i]
url=glue(base_url,station,resource,'start=',{format(start_date,'%Y-%m-%d')},{start_time},'&end=',{format(end_date,'%Y-%m-%d')},{end_time})
page=requests$get(url)
content_2 = pandas_io$loads(content)
df = pandas_io$json_normalize(content_2)
for j in seq_along(content_2$features)
}
temps = data_frame(NULL)
temps = data_frame(NULL)
for (i in seq_along(date_sequence$start)){
start_date = date_sequence$start[i]
end_date = date_sequence$end[i]
url=glue(base_url,station,resource,'start=',{format(start_date,'%Y-%m-%d')},{start_time},'&end=',{format(end_date,'%Y-%m-%d')},{end_time})
page=requests$get(url)
content=page$content
content_2 = pandas_io$loads(content)
df = pandas_io$json_normalize(content_2)
for (j in seq_along(content_2$features)){
record = data_frame(date=content_2$features[[i]]$properties$timestamp[1],
temp=round(content_2$features[[i]]$properties$temperature[1]$value*(9/5)+32,2)))
bind_rows(record,temps)
}
}
record = data_frame(date=content_2$features[[i]]$properties$timestamp[1],
temp=round(content_2$features[[i]]$properties$temperature[1]$value*(9/5)+32,2))))
url=glue(base_url,station,resource,'start=',{format(start_date,'%Y-%m-%d')},{start_time},'&end=',{format(end_date,'%Y-%m-%d')},{end_time})
url
page=requests$get(url)
library(reticulate)
library(tidyverse)
library(glue)
use_virtualenv('instacart3')
pandas = import('pandas')
pandas_io = import('pandas.io.json')
requests = import('requests')
bs4 = import('bs4')
date_sequence = data_frame(
start=seq.Date(from=as.Date('2018-06-01'),
to=lubridate::today()-lubridate::days(1),
by='1 day'),
end=start+lubridate::days(1)
)
station = 'KSFO'
base_url = 'https://api.weather.gov/stations/'
resource = '/observations?'
start_time = 'T00%3A56%3A00%2B00%3A00&'
end_time = 'T23%3A56%3A00%2B00%3A00'
temps = data_frame(NULL)
for (i in seq_along(date_sequence$start)){
start_date = date_sequence$start[i]
end_date = date_sequence$end[i]
url=glue(base_url,station,resource,'start=',{format(start_date,'%Y-%m-%d')},{start_time},'&end=',{format(end_date,'%Y-%m-%d')},{end_time})
page=requests$get(url)
content=page$content
content_2 = pandas_io$loads(content)
df = pandas_io$json_normalize(content_2)
for (j in seq_along(content_2$features)){
record = data_frame(date=content_2$features[[i]]$properties$timestamp[1],
temp=round(content_2$features[[i]]$properties$temperature[1]$value*(9/5)+32,2)))
bind_rows(record,temps)
}
}
record=data_frame(NULL)
for (i in seq_along(date_sequence$start)){
start_date = date_sequence$start[i]
end_date = date_sequence$end[i]
url=glue(base_url,station,resource,'start=',{format(start_date,'%Y-%m-%d')},{start_time},'&end=',{format(end_date,'%Y-%m-%d')},{end_time})
page=requests$get(url)
content=page$content
content_2 = pandas_io$loads(content)
df = pandas_io$json_normalize(content_2)
for (j in seq_along(content_2$features)){
record = data_frame(date=content_2$features[[i]]$properties$timestamp[1],
temp=round(content_2$features[[i]]$properties$temperature[1]$value*(9/5)+32,2)))
bind_rows(record,temps)
}
}
temps = data_frame(NULL)
record=data_frame(NULL)
for (i in seq_along(date_sequence$start)){
start_date = date_sequence$start[i]
end_date = date_sequence$end[i]
url=glue(base_url,station,resource,'start=',{format(start_date,'%Y-%m-%d')},{start_time},'&end=',{format(end_date,'%Y-%m-%d')},{end_time})
page=requests$get(url)
content=page$content
content_2 = pandas_io$loads(content)
df = pandas_io$json_normalize(content_2)
for (j in seq_along(content_2$features)){
record = data_frame(date=content_2$features[[i]]$properties$timestamp[1],
temp=round(content_2$features[[i]]$properties$temperature[1]$value*(9/5)+32,2))
bind_rows(record,temps)
}
}
date_sequence = data_frame(
start=seq.Date(from=as.Date('2019-06-01'),
to=lubridate::today()-lubridate::days(1),
by='1 day'),
end=start+lubridate::days(1)
)
station = 'KSFO'
base_url = 'https://api.weather.gov/stations/'
resource = '/observations?'
start_time = 'T00%3A56%3A00%2B00%3A00&'
end_time = 'T23%3A56%3A00%2B00%3A00'
temps = data_frame(NULL)
record=data_frame(NULL)
for (i in seq_along(date_sequence$start)){
start_date = date_sequence$start[i]
end_date = date_sequence$end[i]
url=glue(base_url,station,resource,'start=',{format(start_date,'%Y-%m-%d')},{start_time},'&end=',{format(end_date,'%Y-%m-%d')},{end_time})
page=requests$get(url)
content=page$content
content_2 = pandas_io$loads(content)
df = pandas_io$json_normalize(content_2)
for (j in seq_along(content_2$features)){
record = data_frame(date=content_2$features[[i]]$properties$timestamp[1],
temp=round(content_2$features[[i]]$properties$temperature[1]$value*(9/5)+32,2))
temps=bind_rows(record,temps)
}
}
record=data.frame(NULL)
temps = data.frame(NULL)
record=data.frame(NULL)
for (i in seq_along(date_sequence$start)){
start_date = date_sequence$start[i]
end_date = date_sequence$end[i]
url=glue(base_url,station,resource,'start=',{format(start_date,'%Y-%m-%d')},{start_time},'&end=',{format(end_date,'%Y-%m-%d')},{end_time})
page=requests$get(url)
content=page$content
content_2 = pandas_io$loads(content)
df = pandas_io$json_normalize(content_2)
for (j in seq_along(content_2$features)){
record = data_frame(date=content_2$features[[i]]$properties$timestamp[1],
temp=round(content_2$features[[i]]$properties$temperature[1]$value*(9/5)+32,2))
temps=bind_rows(record,temps)
}
}
temps = data.frame(NULL)
record=data.frame(NULL)
for (i in seq_along(date_sequence$start)){
start_date = date_sequence$start[i]
end_date = date_sequence$end[i]
url=glue(base_url,station,resource,'start=',{format(start_date,'%Y-%m-%d')},{start_time},'&end=',{format(end_date,'%Y-%m-%d')},{end_time})
page=requests$get(url)
content=page$content
content_2 = pandas_io$loads(content)
df = pandas_io$json_normalize(content_2)
for (j in seq_along(content_2$features)){
record = data_frame(date=content_2$features[[j]]$properties$timestamp[1],
temp=round(content_2$features[[j]]$properties$temperature[1]$value*(9/5)+32,2))
temps=bind_rows(record,temps)
}
}
View(temps)
seq_along(date_sequence$start)
View(record)
temps = data.frame(NULL)
for (i in seq_along(date_sequence$start)){
start_date = date_sequence$start[i]
end_date = date_sequence$end[i]
url=glue(base_url,station,resource,'start=',{format(start_date,'%Y-%m-%d')},{start_time},'&end=',{format(end_date,'%Y-%m-%d')},{end_time})
page=requests$get(url)
content=page$content
content_2 = pandas_io$loads(content)
df = pandas_io$json_normalize(content_2)
for (j in seq_along(content_2$features)){
record = data_frame(date=content_2$features[[j]]$properties$timestamp[1],
temp=round(content_2$features[[j]]$properties$temperature[1]$value*(9/5)+32,2))
temps=bind_rows(record,temps)
}
}
date_sequence = data_frame(
start=seq.Date(from=as.Date('2019-05-01'),
to=lubridate::today()-lubridate::days(1),
by='1 day'),
end=start+lubridate::days(1)
)
station = 'KSFO'
base_url = 'https://api.weather.gov/stations/'
resource = '/observations?'
start_time = 'T00%3A56%3A00%2B00%3A00&'
end_time = 'T23%3A56%3A00%2B00%3A00'
temps = data.frame(NULL)
for (i in seq_along(date_sequence$start)){
start_date = date_sequence$start[i]
end_date = date_sequence$end[i]
url=glue(base_url,station,resource,'start=',{format(start_date,'%Y-%m-%d')},{start_time},'&end=',{format(end_date,'%Y-%m-%d')},{end_time})
page=requests$get(url)
content=page$content
content_2 = pandas_io$loads(content)
df = pandas_io$json_normalize(content_2)
for (j in seq_along(content_2$features)){
record = data_frame(date=content_2$features[[j]]$properties$timestamp[1],
temp=round(content_2$features[[j]]$properties$temperature[1]$value*(9/5)+32,2))
temps=bind_rows(record,temps)
}
}
View(temps)
View(temps)
temps$date=lubridate::parse_date_time(temps$date)
temps$date=lubridate::as.Date(temps$date)
temps$date=as.Date(temps$date)
temps$date=as.Datetime(temps$date)
date_sequence = data_frame(
start=seq.Date(from=as.Date('2019-06-14'),
to=lubridate::today()-lubridate::days(1),
by='1 day'),
end=start+lubridate::days(1)
)
station = 'KSFO'
base_url = 'https://api.weather.gov/stations/'
resource = '/observations?'
start_time = 'T00%3A56%3A00%2B00%3A00&'
end_time = 'T23%3A56%3A00%2B00%3A00'
temps = data.frame(NULL)
for (i in seq_along(date_sequence$start)){
start_date = date_sequence$start[i]
end_date = date_sequence$end[i]
url=glue(base_url,station,resource,'start=',{format(start_date,'%Y-%m-%d')},{start_time},'&end=',{format(end_date,'%Y-%m-%d')},{end_time})
page=requests$get(url)
content=page$content
content_2 = pandas_io$loads(content)
df = pandas_io$json_normalize(content_2)
for (j in seq_along(content_2$features)){
record = data_frame(date=content_2$features[[j]]$properties$timestamp[1],
temp=round(content_2$features[[j]]$properties$temperature[1]$value*(9/5)+32,2))
temps=bind_rows(record,temps)
}
}
temps$date=as.Datetime(temps$date)
temps$date=as.POSIXct(temps$date)
?
?as.POSIXct.POSIXlt
?
?as.POSIXlt
plot(temps$date,temps$temp)
temps$date
temps = data.frame(NULL)
for (i in seq_along(date_sequence$start)){
start_date = date_sequence$start[i]
end_date = date_sequence$end[i]
url=glue(base_url,station,resource,'start=',{format(start_date,'%Y-%m-%d')},{start_time},'&end=',{format(end_date,'%Y-%m-%d')},{end_time})
page=requests$get(url)
content=page$content
content_2 = pandas_io$loads(content)
df = pandas_io$json_normalize(content_2)
for (j in seq_along(content_2$features)){
record = data_frame(date=content_2$features[[j]]$properties$timestamp[1],
temp=round(content_2$features[[j]]$properties$temperature[1]$value*(9/5)+32,2))
temps=bind_rows(record,temps)
}
}
temps$date=lubridate::as_datetime(temps$date)
plot(temps$date,temps$temp)
ggplot(data=temps,x=date,y=temp) + geom_line()
ggplot(data=temps,aes(x=date,y=temp)) + geom_line()
ggplot(data=temps,aes(x=date,y=temp)) + geom_line() + geom_point()
ggplot(data=temps,aes(x=date,y=temp)) +
geom_line() +
geom_point()
date_sequence = data_frame(
start=seq.Date(from=as.Date('2019-06-14'),
to=lubridate::today()-lubridate::days(0),
by='1 day'),
end=start+lubridate::days(1)
)
station = 'KSFO'
base_url = 'https://api.weather.gov/stations/'
resource = '/observations?'
start_time = 'T00%3A56%3A00%2B00%3A00&'
end_time = 'T23%3A56%3A00%2B00%3A00'
temps = data.frame(NULL)
for (i in seq_along(date_sequence$start)){
start_date = date_sequence$start[i]
end_date = date_sequence$end[i]
url=glue(base_url,station,resource,'start=',{format(start_date,'%Y-%m-%d')},{start_time},'&end=',{format(end_date,'%Y-%m-%d')},{end_time})
page=requests$get(url)
content=page$content
content_2 = pandas_io$loads(content)
df = pandas_io$json_normalize(content_2)
for (j in seq_along(content_2$features)){
record = data_frame(date=content_2$features[[j]]$properties$timestamp[1],
temp=round(content_2$features[[j]]$properties$temperature[1]$value*(9/5)+32,2))
temps=bind_rows(record,temps)
}
}
temps$date=lubridate::as_datetime(temps$date)
?
?as.POSIXlt
ggplot(data=temps,aes(x=date,y=temp)) +
geom_line() +
geom_point()
ggplot(data=temps,aes(x=date,y=temp)) +
geom_line() +
geom_point()
temps$date=lubridate::as_datetime(temps$date,tz='America/Los Angeles')
temps$date=lubridate::as_datetime(temps$date,tz='america/los_angeles')
temps$date=lubridate::as_datetime(temps$date,tz='america/Los_Angeles')
ggplot(data=temps,aes(x=date,y=temp)) +
geom_line() +
geom_point()
ggplot(data=temps,aes(x=date,y=temp)) +
geom_line(color='gray') +
geom_point()
ggplot(data=temps,aes(x=date,y=temp)) +
geom_line(color='gray') +
geom_point()
instapy = import('instapy')
library(reticulate)
library(tidyverse)
library(glue)
pandas = import('pandas')
pandas_io = import('pandas.io.json')
requests = import('requests')
instapy = import('instapy')
use_virtualenv('instacart3')
pandas = import('pandas')
pandas_io = import('pandas.io.json')
requests = import('requests')
instapy = import('instapy')
use_virtualenv('instacart3')
instapy = import('instapy')
use_virtualenv('instacart3')
library(reticulate) ## duh :)
library(tidyverse) ## loading this for some data wrangling and data visualization at the end
library(glue) ## loading this to help with creating URLs to hit a web API
use_virtualenv('instacart3')
pandas = import('pandas')
library(reticulate) ## duh :)
library(tidyverse) ## loading this for some data wrangling and data visualization at the end
library(glue) ## loading this to help with creating URLs to hit a web API
use_virtualenv('instacart3')
pandas = import('pandas')
pandas_io = import('pandas.io.json')
requests = import('requests')
pandas$pivot
stations = read_csv('/Users/matthewbrower/git/pyohio_reticulate_rpy2/r/station_identifiers.csv')
base_url = 'https://api.weather.gov/stations/'
resource = '/observations?'
temps = data.frame(NULL)
for (i in seq_along(stations$station_identifier)){
station = stations$station_identifier[i]
url=glue(base_url,station,resource)
page=requests$get(url)
content=page$content
content_2 = pandas_io$loads(content)
df = pandas_io$json_normalize(content_2)
for (j in seq_along(content_2$features)){
record = tibble(date=content_2$features[[j]]$properties$timestamp[1],
temp=round(content_2$features[[j]]$properties$temperature[1]$value*(9/5)+32,2),
station_name=stations$name[i],
station_id = station)
temps=bind_rows(record,temps)
}
}
temps =
temps %>%
filter(date>= as.Date('2019-06-01')) %>%
mutate(date=lubridate::as_datetime(date,tz='America/Los_Angeles'))
ggplot(data=temps,aes(x=date,y=temp)) +
geom_line(color='gray') +
scale_color_gradient(low='blue',high='orange') +
geom_point(aes(color=temp)) +
facet_wrap(~station_name)
library(reticulate) ## duh :)
library(tidyverse) ## loading for data wrangling and visualization
library(glue) ## loading this to help with creating URLs to hit a web API
list(pandas)
head(stations)
stations
stations = read_csv('/Users/matthewbrower/git/pyohio_reticulate_rpy2/r/station_identifiers.csv')
stations
```{r, warning=FALSE, message=FALSE}
stations = read_csv('/Users/matthewbrower/git/pyohio_reticulate_rpy2/r/station_identifiers.csv')
library(reticulate) ## load the reticulate library
library(tidyverse) ## loading for data wrangling and visualization
library(glue) ## loading this to help with creating URLs to hit a web API
use_virtualenv('instacart3')
pandas = import('pandas')
pandas_io = import('pandas.io.json')
requests = import('requests')
pandas$pivot
stations = read_csv('/Users/matthewbrower/git/pyohio_reticulate_rpy2/r/station_identifiers.csv')
stations
base_url = 'https://api.weather.gov/stations/'
resource = '/observations?'
temps = data.frame(NULL)
for (i in seq_along(stations$station_identifier)){
station = stations$station_identifier[i]
url=glue(base_url,station,resource)
page=requests$get(url)
content=page$content
content_2 = pandas_io$loads(content)
df = pandas_io$json_normalize(content_2)
for (j in seq_along(content_2$features)){
record = tibble(date=content_2$features[[j]]$properties$timestamp[1],
temp=round(content_2$features[[j]]$properties$temperature[1]$value*(9/5)+32,2),
station_name=stations$name[i],
station_id = station)
temps=bind_rows(record,temps)
}
}
temps =
temps %>%
filter(date>= as.Date('2019-06-01')) %>%
mutate(date=lubridate::as_datetime(date,tz='America/Los_Angeles'))
ggplot(data=temps,aes(x=date,y=temp)) +
geom_line(color='gray') +
scale_color_gradient(low='blue',high='orange') +
geom_point(aes(color=temp)) +
facet_wrap(~station_name)
library(reticulate) ## load the reticulate library
library(tidyverse) ## loading for data wrangling and visualization
library(glue) ## loading this to help with creating URLs to hit a web API
use_virtualenv('instacart3')
pandas = import('pandas')
library(reticulate) ## load the reticulate library
library(tidyverse) ## loading for data wrangling and visualization
library(glue) ## loading this to help with creating URLs to hit a web API
use_virtualenv('instacart3')
pandas = import('pandas')
install.packages(c("glue", "lubridate", "reticulate", "tidyverse"))
stations = read_csv('/Users/matthewbrower/git/pyohio_reticulate_rpy2/r/reticulate_walkthrough/data/station_identifiers.csv')
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "man/figures/README-",
out.width = "120%",
dpi = 200
)
library(reticulate) ## load the reticulate library
library(tidyverse) ## loading for data wrangling and visualization
library(glue) ## loading this to help with creating URLs to hit a web API
use_virtualenv('instacart3')
pandas = import('pandas')
pandas_io = import('pandas.io.json')
requests = import('requests')
pandas$pivot
stations = read_csv('/Users/matthewbrower/git/pyohio_reticulate_rpy2/r/reticulate_walkthrough/data/station_identifiers.csv')
stations
base_url = 'https://api.weather.gov/stations/'
resource = '/observations?'
temps = data.frame(NULL)
for (i in seq_along(stations$station_identifier)){
station = stations$station_identifier[i]
url=glue(base_url,station,resource)
page=requests$get(url)
content=page$content
content_2 = pandas_io$loads(content)
df = pandas_io$json_normalize(content_2)
for (j in seq_along(content_2$features)){
record = tibble(date=content_2$features[[j]]$properties$timestamp[1],
temp=round(content_2$features[[j]]$properties$temperature[1]$value*(9/5)+32,2),
station_name=stations$name[i],
station_id = station)
temps=bind_rows(record,temps)
}
}
temps =
temps %>%
filter(date>= as.Date('2019-06-01')) %>%
mutate(date=lubridate::as_datetime(date,tz='America/Los_Angeles'))
ggplot(data=temps,aes(x=date,y=temp)) +
geom_line(color='gray') +
scale_color_gradient(low='blue',high='orange') +
geom_point(aes(color=temp)) +
facet_wrap(~stringr::str_wrap(station_name))
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "man/figures/README-",
out.width = "120%",
dpi = 200
)
ggplot(data=temps,aes(x=date,y=temp)) +
geom_line(color='gray') +
scale_color_gradient(low='blue',high='orange') +
geom_point(aes(color=temp)) +
facet_wrap(~stringr::str_wrap(station_name,25))
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "man/figures/README-",
out.width = "120%",
out.height = '200%',
dpi = 200
)
stations = read_csv('/Users/matthewbrower/git/pyohio_reticulate_rpy2/r/reticulate_walkthrough/data/station_identifiers.csv')
