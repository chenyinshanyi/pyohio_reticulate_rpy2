content=page$content
content_2 = pandas_io$loads(content)
df = pandas_io$json_normalize(content_2)
for (j in seq_along(content_2$features)){
record = tibble(date=content_2$features[[j]]$properties$timestamp[1],
temp=round(content_2$features[[j]]$properties$temperature[1]$value*(9/5)+32,2),
station_name=stations$name[i],
station_id = station)
temps=bind_rows(record,temps)
}
}
temps =
temps %>%
filter(date>= as.Date('2019-06-01')) %>%
mutate(date=lubridate::as_datetime(date,tz='America/Los_Angeles'))
ggplot(data=temps,aes(x=date,y=temp)) +
geom_line(color='gray') +
scale_color_gradient(low='blue',high='orange') +
geom_point(aes(color=temp)) +
facet_wrap(~station_name)
library(reticulate) ## duh :)
library(tidyverse) ## loading for data wrangling and visualization
library(glue) ## loading this to help with creating URLs to hit a web API
list(pandas)
head(stations)
stations
stations = read_csv('/Users/matthewbrower/git/pyohio_reticulate_rpy2/r/station_identifiers.csv')
stations
```{r, warning=FALSE, message=FALSE}
stations = read_csv('/Users/matthewbrower/git/pyohio_reticulate_rpy2/r/station_identifiers.csv')
library(reticulate) ## load the reticulate library
library(tidyverse) ## loading for data wrangling and visualization
library(glue) ## loading this to help with creating URLs to hit a web API
use_virtualenv('instacart3')
pandas = import('pandas')
pandas_io = import('pandas.io.json')
requests = import('requests')
pandas$pivot
stations = read_csv('/Users/matthewbrower/git/pyohio_reticulate_rpy2/r/station_identifiers.csv')
stations
base_url = 'https://api.weather.gov/stations/'
resource = '/observations?'
temps = data.frame(NULL)
for (i in seq_along(stations$station_identifier)){
station = stations$station_identifier[i]
url=glue(base_url,station,resource)
page=requests$get(url)
content=page$content
content_2 = pandas_io$loads(content)
df = pandas_io$json_normalize(content_2)
for (j in seq_along(content_2$features)){
record = tibble(date=content_2$features[[j]]$properties$timestamp[1],
temp=round(content_2$features[[j]]$properties$temperature[1]$value*(9/5)+32,2),
station_name=stations$name[i],
station_id = station)
temps=bind_rows(record,temps)
}
}
temps =
temps %>%
filter(date>= as.Date('2019-06-01')) %>%
mutate(date=lubridate::as_datetime(date,tz='America/Los_Angeles'))
ggplot(data=temps,aes(x=date,y=temp)) +
geom_line(color='gray') +
scale_color_gradient(low='blue',high='orange') +
geom_point(aes(color=temp)) +
facet_wrap(~station_name)
library(reticulate) ## load the reticulate library
library(tidyverse) ## loading for data wrangling and visualization
library(glue) ## loading this to help with creating URLs to hit a web API
use_virtualenv('instacart3')
pandas = import('pandas')
library(reticulate) ## load the reticulate library
library(tidyverse) ## loading for data wrangling and visualization
library(glue) ## loading this to help with creating URLs to hit a web API
use_virtualenv('instacart3')
pandas = import('pandas')
install.packages(c("glue", "lubridate", "reticulate", "tidyverse"))
stations = read_csv('/Users/matthewbrower/git/pyohio_reticulate_rpy2/r/reticulate_walkthrough/data/station_identifiers.csv')
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "man/figures/README-",
out.width = "120%",
dpi = 200
)
library(reticulate) ## load the reticulate library
library(tidyverse) ## loading for data wrangling and visualization
library(glue) ## loading this to help with creating URLs to hit a web API
use_virtualenv('instacart3')
pandas = import('pandas')
pandas_io = import('pandas.io.json')
requests = import('requests')
pandas$pivot
stations = read_csv('/Users/matthewbrower/git/pyohio_reticulate_rpy2/r/reticulate_walkthrough/data/station_identifiers.csv')
stations
base_url = 'https://api.weather.gov/stations/'
resource = '/observations?'
temps = data.frame(NULL)
for (i in seq_along(stations$station_identifier)){
station = stations$station_identifier[i]
url=glue(base_url,station,resource)
page=requests$get(url)
content=page$content
content_2 = pandas_io$loads(content)
df = pandas_io$json_normalize(content_2)
for (j in seq_along(content_2$features)){
record = tibble(date=content_2$features[[j]]$properties$timestamp[1],
temp=round(content_2$features[[j]]$properties$temperature[1]$value*(9/5)+32,2),
station_name=stations$name[i],
station_id = station)
temps=bind_rows(record,temps)
}
}
temps =
temps %>%
filter(date>= as.Date('2019-06-01')) %>%
mutate(date=lubridate::as_datetime(date,tz='America/Los_Angeles'))
ggplot(data=temps,aes(x=date,y=temp)) +
geom_line(color='gray') +
scale_color_gradient(low='blue',high='orange') +
geom_point(aes(color=temp)) +
facet_wrap(~stringr::str_wrap(station_name))
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "man/figures/README-",
out.width = "120%",
dpi = 200
)
ggplot(data=temps,aes(x=date,y=temp)) +
geom_line(color='gray') +
scale_color_gradient(low='blue',high='orange') +
geom_point(aes(color=temp)) +
facet_wrap(~stringr::str_wrap(station_name,25))
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "man/figures/README-",
out.width = "120%",
out.height = '200%',
dpi = 200
)
stations = read_csv('/Users/matthewbrower/git/pyohio_reticulate_rpy2/r/reticulate_walkthrough/data/station_identifiers.csv')
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "man/figures/README-",
out.width = "120%",
out.height = '200%',
dpi = 200
)
use_virtualenv('instacart3')
library(reticulate) ## load the reticulate library
library(tidyverse) ## loading for data wrangling and visualization
library(glue) ## loading this to help with creating URLs to hit a web API
use_virtualenv('instacart3')
pandas = import('pandas')
requests = import('requests')
pandas = reticulate::import('pandas')
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "man/figures/README-",
out.width = "120%",
out.height = '200%',
dpi = 200
)
library(reticulate) ## load the reticulate library
library(tidyverse) ## loading for data wrangling and visualization
library(glue) ## loading this to help with creating URLs to hit a web API
use_virtualenv('instacart3')
virtualenv_install('instacart3',c('pandas','requests'))
virtualenv_install('instacart3','pandas'))
virtualenv_install('instacart3','pandas')
virtualenv_install('pandas')
install.packages("reticulate")
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "man/figures/README-",
out.width = "120%",
out.height = '200%',
dpi = 200
)
use_virtualenv()
library(reticulate) ## load the reticulate library
library(tidyverse) ## loading for data wrangling and visualization
library(glue) ## loading this to help with creating URLs to hit a web API
use_virtualenv()
virtualenv_install('pandas')
py_available()
use_python()
Sys.which
Sys.which("python")
py_discover_config()
py_discover_config()
reticulate::py_discover_config()
reticulate::py_available()
reticulate::py_available(initialize = T)
reticulate::py_discover_config()
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "man/figures/README-",
out.width = "120%",
out.height = '200%',
dpi = 200
)
library(reticulate) ## load the reticulate library
library(tidyverse) ## loading for data wrangling and visualization
library(glue) ## loading this to help with creating URLs to hit a web API
pandas = import('pandas')
virtualenv_install('pandas')
use_virtualenv('instacart3')
virtualenv_install('pandas')
pandas = import('pandas')
requests = import('requests')
pandas_io = import('pandas.io.json')
reticulate::py_discover_config()
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "man/figures/README-",
out.width = "120%",
out.height = '200%',
dpi = 200
)
library(reticulate) ## load the reticulate library
library(tidyverse) ## loading for data wrangling and visualization
library(glue) ## loading this to help with creating URLs to hit a web API
use_virtualenv('instacart3')
virtualenv_install('pandas')
pandas = import('pandas')
requests = import('requests')
pandas_io = import('pandas.io.json')
pandas$pivot
stations = read_csv('/Users/matthewbrower/git/pyohio_reticulate_rpy2/r/reticulate_walkthrough/data/station_identifiers.csv')
stations
base_url = 'https://api.weather.gov/stations/'
resource = '/observations?'
station = NULL
temps = data.frame(NULL)
for (i in seq_along(stations$station_identifier)){
station = stations$station_identifier[i]
url=glue(base_url,station,resource)
page=requests$get(url)
content=page$content
content_2 = pandas_io$loads(content)
df = pandas_io$json_normalize(content_2)
for (j in seq_along(content_2$features)){
record = tibble(date=content_2$features[[j]]$properties$timestamp[1],
temp=round(content_2$features[[j]]$properties$temperature[1]$value*(9/5)+32,2),
station_name=stations$short_name[i],
station_id = station)
temps=bind_rows(record,temps)
}
}
View(df)
View(record)
station = stations$station_identifier[i]
url=glue(base_url,station,resource)
page=requests$get(url)
content_2 = pandas_io$loads(content)
df = pandas_io$json_normalize(content_2)
for (j in seq_along(content_2$features)){
record = tibble(date=content_2$features[[j]]$properties$timestamp[1],
temp=round(content_2$features[[j]]$properties$temperature[1]$value*(9/5)+32,2),
station_name=stations$short_name[i],
station_id = station)
temps=bind_rows(record,temps)
}
record = tibble(date=content_2$features[[j]]$properties$timestamp[1],
temp=round(content_2$features[[j]]$properties$temperature[1]$value*(9/5)+32,2),
station_name=stations$short_name[i],
station_id = station)
pandas_io$json_normalize(content_2)
View(df)
View(df[[1]][[1]])
use_virtualenv('instacart3')
py_available()
py_config()
use_virtualenv('instacart3',required=T)
use_virtualenv('instacart3',required=T)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "man/figures/README-",
out.width = "120%",
out.height = '200%',
dpi = 200
)
library(reticulate) ## load the reticulate library
library(tidyverse) ## loading for data wrangling and visualization
library(glue) ## loading this to help with creating URLs to hit a web API
use_virtualenv('instacart3',required=T)
virtualenv_install('pandas')
pandas = import('pandas')
requests = import('requests')
pandas_io = import('pandas.io.json')
pandas$pivot
stations = read_csv('/Users/matthewbrower/git/pyohio_reticulate_rpy2/r/reticulate_walkthrough/data/station_identifiers.csv')
stations
base_url = 'https://api.weather.gov/stations/'
resource = '/observations?'
station = NULL
temps = data.frame(NULL)
for (i in seq_along(stations$station_identifier)){
station = stations$station_identifier[i]
url=glue(base_url,station,resource)
page=requests$get(url)
content=page$content
content_2 = pandas_io$loads(content)
df = pandas_io$json_normalize(content_2)
for (j in seq_along(content_2$features)){
record = tibble(date=content_2$features[[j]]$properties$timestamp[1],
temp=round(content_2$features[[j]]$properties$temperature[1]$value*(9/5)+32,2),
station_name=stations$short_name[i],
station_id = station)
temps=bind_rows(record,temps)
}
}
temps =
temps %>%
filter(date>= as.Date('2019-06-01')) %>%
mutate(date=lubridate::as_datetime(date,tz='America/Los_Angeles'))
ggplot(data=temps,aes(x=date,y=temp)) +
geom_line(color='gray') +
scale_color_gradient(low='blue',high='orange') +
geom_point(aes(color=temp)) +
facet_wrap(~station_name)
stations = read_csv('data/station_identifiers.csv')
View(content)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "man/figures/README-",
out.width = "120%",
out.height = '200%',
dpi = 500
)
install.packages("knitr")
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "man/figures/README-",
out.width = "120%",
out.height = '200%',
dpi = 500
)
library(reticulate) ## load the reticulate library
library(tidyverse) ## loading for data wrangling and visualization
install.packages("tidyverse")
install.packages("glue")
install.packages("lubridate")
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "man/figures/README-",
out.width = "120%",
out.height = '200%',
dpi = 500
)
library(reticulate) ## load the reticulate library
library(tidyverse) ## loading for data wrangling and visualization
library(glue) ## loading this to help with creating URLs to hit a web API
library(lubridate) ## loading this for help with date operations
virtualenv_create("r_py3_venv", python = "/usr/local/bin/python3")
use_virtualenv("r_py3_venv")
pandas = import('pandas')
py_install(c("pandas","requests") envname = "r_py3_venv")
py_install(c("pandas","requests"), envname = "r_py3_venv")
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "man/figures/README-",
out.width = "120%",
out.height = '200%',
dpi = 500
)
library(reticulate) ## load the reticulate library
library(tidyverse) ## loading for data wrangling and visualization
library(glue) ## loading this to help with creating URLs to hit a web API
library(lubridate) ## loading this for help with date operations
virtualenv_create("r_py3_venv", python = "/usr/local/bin/python3")
use_virtualenv("r_py3_venv")
pandas = import('pandas')
py_install(c("pandas","requests"), envname = "r_py3_venv")
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "man/figures/README-",
out.width = "120%",
out.height = '200%',
dpi = 500
)
library(reticulate) ## load the reticulate library
library(tidyverse) ## loading for data wrangling and visualization
library(glue) ## loading this to help with creating URLs to hit a web API
library(lubridate) ## loading this for help with date operations
virtualenv_create("r_py3_venv", python = "/usr/local/bin/python3")
use_virtualenv("r_py3_venv")
pandas = import('pandas')
pandas = import('pandas')
requests = import('requests')
pandas_io = import('pandas.io.json')
use_virtualenv("r_py3_venv")
py_config()
py_available()
py_config_error_message()
knitr::opts_chunk$set(
collapse = TRUE,
comment = "",
fig.path = "man/figures/README-",
out.width = "120%",
out.height = '200%',
dpi = 500
)
temperature_data =
temperature_data %>%
filter(as.Date(date)>=as.Date(today()-days(3))) %>%
mutate(observation_date_time_local=as_datetime(date,tz='America/Los_Angeles'))
library(tidyverse) ## loading for data wrangling and visualization
library(glue) ## loading this to help with creating URLs to hit a web API
library(lubridate) ## loading this for help with date operations
library(reticulate) ## load the reticulate library
library(reticulate) ## load the reticulate library
library(tidyverse) ## loading for data wrangling and visualization
library(glue) ## loading this to help with creating URLs to hit a web API
library(glue) ## loading this to help with creating URLs to hit a web API
library(lubridate) ## loading this for help with date operations
knitr::opts_chunk$set(
collapse = TRUE,
comment = "",
fig.path = "man/figures/README-",
out.width = "120%",
out.height = '200%',
dpi = 500
)
library(reticulate) ## load the reticulate library
library(tidyverse) ## loading for data wrangling and visualization
library(glue) ## loading this to help with creating URLs to hit a web API
library(lubridate) ## loading this for help with date operations
virtualenv_create("r_py3_venv",
python = "/usr/local/bin/python3")
use_virtualenv("r_py3_venv")
py_eval('[867,"-",5309].pop()')
pandas = import('pandas')
requests = import('requests')
pandas_io = import('pandas.io.json')
pandas$pivot
station_list = read_csv('data/station_identifiers.csv')
station_list
base_url = 'https://api.weather.gov/stations/'
resource = '/observations?'
station = NULL
temperature_data = data.frame(NULL)
## for every row `i` in my dataframe of stations, I want to do the following
for (i in seq_along(station_list$station_identifier)){
## establish the station identifier I need to use in the API call
station = station_list$station_identifier[i]
## create the URL we'll use to make the API request
url=glue(base_url,station,resource)
## use Python's `requests` library to grab the contents of the URL I made from the web
page=requests$get(url)
## exclude superfluous information not containing data I care about (i.e. HTPP response, etc)
content=page$content
## use `pandas.io` from Python to extract and normalize the JSON from the API request
content_pandas_io = pandas_io$loads(content)
## at this point, I have a normalized JSON object stored as a list in R
## there is a element in this list for each observation recorded from this station
## for every element `j`, I want to extract the time the observation was recorded and the temperature that was recorded (in Fahrenheit)
for (j in seq_along(content_pandas_io$features)){
## for each observation, I want a one-row dataframe with columns for date, station, and temperature
record = tibble(date=content_pandas_io$features[[j]]$properties$timestamp[1],
temperature=round(content_pandas_io$features[[j]]$properties$temperature[1]$value*(9/5)+32,2),
station_name=station_list$short_name[i],
station_id = station)
## once I have that, I can append this newly-created row to a dataframe containing the final results
temperature_data=bind_rows(record,temperature_data)
}
}
temperature_data =
temperature_data %>%
filter(as.Date(date)>=as.Date(today()-days(3))) %>%
mutate(observation_date_time_local=as_datetime(date,tz='America/Los_Angeles'))
ggplot(data=temperature_data,
aes(x=observation_date_time_local,
y=temperature)) +
geom_line(color='gray') +
scale_color_gradient(low='blue',
high='orange') +
geom_point(aes(color=temperature)) +
facet_wrap(~station_name)
sessionInfo()
temperature_data =
temperature_data %>%
filter(as.Date(date)>=as.Date(today()-days(3))) %>%
mutate(observation_date_time_local=as_datetime(date,tz='America/Los_Angeles'))
ggplot(data=temperature_data,
aes(x=observation_date_time_local,
y=temperature)) +
geom_line(color='gray') +
scale_color_gradient(low='blue',
high='orange') +
geom_point(aes(color=temperature)) +
facet_wrap(~station_name)
py_eval('[867,"-",5309].pop()')
py_install(c("pandas",
"requests",
"pandas.io"),
envname = "r_py3_venv")
